{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlos-alves-one/-Amazon-Review-NLP/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goldsmiths University of London\n",
        "### MSc. Data Science and Artificial Intelligence\n",
        "### Module: Natural Language Processing\n",
        "### Author: Carlos Manuel De Oliveira Alves\n",
        "### Student: cdeol003\n",
        "### Coursework Project"
      ],
      "metadata": {
        "id": "GpWkS9g3XYaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection"
      ],
      "metadata": {
        "id": "LPQR5k8DZBHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data"
      ],
      "metadata": {
        "id": "Rdq1tWxhdNyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports the 'drive' module from 'google.colab' and mounts the Google Drive to\n",
        "# the '/content/drive' directory in the Colab environment.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAfyl1E4Xhig",
        "outputId": "1b9bad95-a175-4886-87e0-34b63d0a9bcf"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset source: https://www.kaggle.com/datasets/akudnaver/amazon-reviews-dataset\n",
        "\n",
        "License: Unknown"
      ],
      "metadata": {
        "id": "UriCgHuhnXaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pandas library and give it the alias 'pd' for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset Amazon Review Details from Google Drive\n",
        "data_path = '/content/drive/MyDrive/amazon_project/amazon-review-details.csv'\n",
        "amazon_data = pd.read_csv(data_path)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "amazon_data.head(3).T\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ShHZnYEod2V1",
        "outputId": "dde26cdf-f882-4532-a381-027bcddfba6f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                        0  \\\n",
              "report_date                                                    2019-01-02   \n",
              "online_store                                                  FRESHAMAZON   \n",
              "upc                                                         8718114216478   \n",
              "retailer_product_code                                          B0142CI6FC   \n",
              "brand                                                       Dove Men+Care   \n",
              "category                                                    Personal Care   \n",
              "sub_category                                                         Deos   \n",
              "product_description     Dove Men+Care Extra Fresh Anti-perspirant Deod...   \n",
              "review_date                                                    2019-01-01   \n",
              "review_rating                                                           5   \n",
              "review_title                                       Dove Men’s + Deodorant   \n",
              "review_text             As you get older, you know what you like and w...   \n",
              "is_competitor                                                           0   \n",
              "manufacturer                                              Unilever Global   \n",
              "market                                                                 UK   \n",
              "matched_keywords                                                      NaN   \n",
              "time_of_publication                                                   NaN   \n",
              "url                     http://www.amazon.co.uk/gp/customer-reviews/RE...   \n",
              "review_type                                                       Organic   \n",
              "parent_review                                                       Child   \n",
              "manufacturers_response                                                NaN   \n",
              "dimension1                                                           Deos   \n",
              "dimension2                                 Male Anti-Perspirant Deodorant   \n",
              "dimension3                            COTC Male Anti-Perspirant Deodorant   \n",
              "dimension4                                                            NaN   \n",
              "dimension5                                                            NaN   \n",
              "dimension6                                                            NaN   \n",
              "dimension7                            COTC Male Anti-Perspirant Deodorant   \n",
              "dimension8                                               Core of the Core   \n",
              "verified_purchase                                                    True   \n",
              "helpful_review_count                                                    0   \n",
              "review_hash_id                       3f129b02-ea76-0323-bd59-235d97a4f83f   \n",
              "\n",
              "                                                                        1  \\\n",
              "report_date                                                    2019-01-03   \n",
              "online_store                                                  FRESHAMAZON   \n",
              "upc                                                         5000184201199   \n",
              "retailer_product_code                                          B014DFNNRY   \n",
              "brand                                                             Marmite   \n",
              "category                                                            Foods   \n",
              "sub_category                                                      Savoury   \n",
              "product_description                    Marmite  Spread Yeast Extract 500g   \n",
              "review_date                                                    2019-01-02   \n",
              "review_rating                                                           5   \n",
              "review_title                                   Great for a marmite lover!   \n",
              "review_text             Three gigantic marmite jars that will last pro...   \n",
              "is_competitor                                                           0   \n",
              "manufacturer                                              Unilever Global   \n",
              "market                                                                 UK   \n",
              "matched_keywords                                                      NaN   \n",
              "time_of_publication                                                   NaN   \n",
              "url                     http://www.amazon.co.uk/gp/customer-reviews/R1...   \n",
              "review_type                                                       Organic   \n",
              "parent_review                                                       Child   \n",
              "manufacturers_response                                                NaN   \n",
              "dimension1                                                        Savoury   \n",
              "dimension2                                             COTC Yeast Extract   \n",
              "dimension3                                             COTC Yeast Extract   \n",
              "dimension4                                                            NaN   \n",
              "dimension5                                                            NaN   \n",
              "dimension6                                                            NaN   \n",
              "dimension7                                             COTC Yeast Extract   \n",
              "dimension8                                               Core of the Core   \n",
              "verified_purchase                                                    True   \n",
              "helpful_review_count                                                    0   \n",
              "review_hash_id                       d7f3b9aa-e8b3-626d-683b-374e201c8315   \n",
              "\n",
              "                                                                        2  \n",
              "report_date                                                    2019-01-03  \n",
              "online_store                                                  FRESHAMAZON  \n",
              "upc                                                         5000184201199  \n",
              "retailer_product_code                                          B014DFNNRY  \n",
              "brand                                                             Marmite  \n",
              "category                                                            Foods  \n",
              "sub_category                                                      Savoury  \n",
              "product_description                    Marmite  Spread Yeast Extract 500g  \n",
              "review_date                                                    2019-01-02  \n",
              "review_rating                                                           4  \n",
              "review_title                                                 Vitamin B12.  \n",
              "review_text                                                     Excellent  \n",
              "is_competitor                                                           0  \n",
              "manufacturer                                              Unilever Global  \n",
              "market                                                                 UK  \n",
              "matched_keywords                                                      NaN  \n",
              "time_of_publication                                                   NaN  \n",
              "url                     http://www.amazon.co.uk/gp/customer-reviews/RD...  \n",
              "review_type                                                       Organic  \n",
              "parent_review                                                       Child  \n",
              "manufacturers_response                                                NaN  \n",
              "dimension1                                                        Savoury  \n",
              "dimension2                                             COTC Yeast Extract  \n",
              "dimension3                                             COTC Yeast Extract  \n",
              "dimension4                                                            NaN  \n",
              "dimension5                                                            NaN  \n",
              "dimension6                                                            NaN  \n",
              "dimension7                                             COTC Yeast Extract  \n",
              "dimension8                                               Core of the Core  \n",
              "verified_purchase                                                    True  \n",
              "helpful_review_count                                                    0  \n",
              "review_hash_id                       e58a523d-0155-a366-f107-7ac6817ac3b7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-df2629a6-7c43-4181-a8e0-e4111cbeb436\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>report_date</th>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>2019-01-03</td>\n",
              "      <td>2019-01-03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>online_store</th>\n",
              "      <td>FRESHAMAZON</td>\n",
              "      <td>FRESHAMAZON</td>\n",
              "      <td>FRESHAMAZON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>upc</th>\n",
              "      <td>8718114216478</td>\n",
              "      <td>5000184201199</td>\n",
              "      <td>5000184201199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retailer_product_code</th>\n",
              "      <td>B0142CI6FC</td>\n",
              "      <td>B014DFNNRY</td>\n",
              "      <td>B014DFNNRY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>brand</th>\n",
              "      <td>Dove Men+Care</td>\n",
              "      <td>Marmite</td>\n",
              "      <td>Marmite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category</th>\n",
              "      <td>Personal Care</td>\n",
              "      <td>Foods</td>\n",
              "      <td>Foods</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sub_category</th>\n",
              "      <td>Deos</td>\n",
              "      <td>Savoury</td>\n",
              "      <td>Savoury</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>product_description</th>\n",
              "      <td>Dove Men+Care Extra Fresh Anti-perspirant Deod...</td>\n",
              "      <td>Marmite  Spread Yeast Extract 500g</td>\n",
              "      <td>Marmite  Spread Yeast Extract 500g</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_date</th>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>2019-01-02</td>\n",
              "      <td>2019-01-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_rating</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_title</th>\n",
              "      <td>Dove Men’s + Deodorant</td>\n",
              "      <td>Great for a marmite lover!</td>\n",
              "      <td>Vitamin B12.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_text</th>\n",
              "      <td>As you get older, you know what you like and w...</td>\n",
              "      <td>Three gigantic marmite jars that will last pro...</td>\n",
              "      <td>Excellent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>is_competitor</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>manufacturer</th>\n",
              "      <td>Unilever Global</td>\n",
              "      <td>Unilever Global</td>\n",
              "      <td>Unilever Global</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>market</th>\n",
              "      <td>UK</td>\n",
              "      <td>UK</td>\n",
              "      <td>UK</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>matched_keywords</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time_of_publication</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>url</th>\n",
              "      <td>http://www.amazon.co.uk/gp/customer-reviews/RE...</td>\n",
              "      <td>http://www.amazon.co.uk/gp/customer-reviews/R1...</td>\n",
              "      <td>http://www.amazon.co.uk/gp/customer-reviews/RD...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_type</th>\n",
              "      <td>Organic</td>\n",
              "      <td>Organic</td>\n",
              "      <td>Organic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>parent_review</th>\n",
              "      <td>Child</td>\n",
              "      <td>Child</td>\n",
              "      <td>Child</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>manufacturers_response</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dimension1</th>\n",
              "      <td>Deos</td>\n",
              "      <td>Savoury</td>\n",
              "      <td>Savoury</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dimension2</th>\n",
              "      <td>Male Anti-Perspirant Deodorant</td>\n",
              "      <td>COTC Yeast Extract</td>\n",
              "      <td>COTC Yeast Extract</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dimension3</th>\n",
              "      <td>COTC Male Anti-Perspirant Deodorant</td>\n",
              "      <td>COTC Yeast Extract</td>\n",
              "      <td>COTC Yeast Extract</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dimension4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dimension5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dimension6</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dimension7</th>\n",
              "      <td>COTC Male Anti-Perspirant Deodorant</td>\n",
              "      <td>COTC Yeast Extract</td>\n",
              "      <td>COTC Yeast Extract</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dimension8</th>\n",
              "      <td>Core of the Core</td>\n",
              "      <td>Core of the Core</td>\n",
              "      <td>Core of the Core</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>verified_purchase</th>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>helpful_review_count</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>review_hash_id</th>\n",
              "      <td>3f129b02-ea76-0323-bd59-235d97a4f83f</td>\n",
              "      <td>d7f3b9aa-e8b3-626d-683b-374e201c8315</td>\n",
              "      <td>e58a523d-0155-a366-f107-7ac6817ac3b7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df2629a6-7c43-4181-a8e0-e4111cbeb436')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-df2629a6-7c43-4181-a8e0-e4111cbeb436 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-df2629a6-7c43-4181-a8e0-e4111cbeb436');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c7f60413-f3e6-49c2-b1f6-fe0834031904\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7f60413-f3e6-49c2-b1f6-fe0834031904')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c7f60413-f3e6-49c2-b1f6-fe0834031904 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting the first review text from the 'review_text' column of the amazon_data dataframe\n",
        "data = amazon_data['review_text'].values[0]\n",
        "data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "NqZ0JPq1gSdD",
        "outputId": "cff37e6c-283f-472a-fe50-2b54510fca4a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'As you get older, you know what you like and what is suitable for your body. I like all Dove products. Gives you that fresh all over, wide awake feeling and no dandruff or flakey skin. No smelly a/pits!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lexical Analysis"
      ],
      "metadata": {
        "id": "hVFICOgRVFzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word Tokenization\n",
        "\n",
        "> The code snippet below first imports the NLTK library, a popular library for natural language processing in Python. Second downloads the 'punkt' package, which contains pre-trained models for tokenizing sentences, an essential step in many text processing tasks."
      ],
      "metadata": {
        "id": "2hxRuac2VPDN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Natural Language Toolkit (nltk) library. This library is used for working with human language data (text) in Python\n",
        "import nltk\n",
        "\n",
        "# Download the 'punkt' tokenizer models. This is necessary for sentence tokenization, which is a part of the nltk library's functionality\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx8Eb4eBTOeY",
        "outputId": "cf814edc-e1b8-4223-ea86-b1f9304b39fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> This code snippet is used for natural language processing. The `word_tokenize` function takes a string (stored in the variable `data`) and splits it into its constituent words, a process known as tokenization. This is often a preliminary step in text-processing tasks like language modelling, sentiment analysis, or information extraction. Note that for this code to work, `data` should be a string variable containing some text."
      ],
      "metadata": {
        "id": "VFLmvpIaozH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# From the nltk.tokenize module, import the sent_tokenize and word_tokenize functions\n",
        "# sent_tokenize is used for splitting text into sentences, and word_tokenize is used for splitting sentences into words\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "# Use the word_tokenize function to split the content of the variable 'data' into individual words\n",
        "# This assumes 'data' is a string containing natural language text\n",
        "# The result, a list of tokenized words, is then printed to the console\n",
        "print(word_tokenize(data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxOEzhw5SlzU",
        "outputId": "fa19f962-ef48-4149-9665-4d4132a7980c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['As', 'you', 'get', 'older', ',', 'you', 'know', 'what', 'you', 'like', 'and', 'what', 'is', 'suitable', 'for', 'your', 'body', '.', 'I', 'like', 'all', 'Dove', 'products', '.', 'Gives', 'you', 'that', 'fresh', 'all', 'over', ',', 'wide', 'awake', 'feeling', 'and', 'no', 'dandruff', 'or', 'flakey', 'skin', '.', 'No', 'smelly', 'a/pits', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence Tokenization\n",
        "\n",
        "> This code snippet differs from the previous one by using sent_tokenize instead of word_tokenize. The sent_tokenize function takes a string of text (provided in the variable data) and splits it into its constituent sentences. This is a common first step in text analysis when dealing with more significant text documents, as it helps in breaking down the text into more manageable units for further processing, like language modelling, sentiment analysis, or summarization. Again, data should be a string variable containing text for this code to function as intended."
      ],
      "metadata": {
        "id": "sxHco2_5VtiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the sent_tokenize function to split the content of the variable 'data' into individual sentences\n",
        "# This assumes 'data' is a string containing natural language text\n",
        "# The result, a list of tokenized sentences, is then printed to the console\n",
        "print(sent_tokenize(data))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luEro0lKVwVD",
        "outputId": "40bb2a12-4f42-4d44-8a02-aac90e3d6c5c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['As you get older, you know what you like and what is suitable for your body.', 'I like all Dove products.', 'Gives you that fresh all over, wide awake feeling and no dandruff or flakey skin.', 'No smelly a/pits!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Store Words and Sentences\n",
        "\n",
        "> In this code snippet, we perform two tokenisation types on the exact text (data): sentence tokenisation and word tokenisation. First, the text is split into sentences and stored in the variable phrases. Then, the exact text is split into words and stored in the variable words. Finally, both the tokenised sentences and words are printed. This approach is practical when we need to analyse the text at both the sentence and word levels.\n"
      ],
      "metadata": {
        "id": "juIcb6kvYHRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the sent_tokenize function to split the content of the variable 'data' into individual sentences\n",
        "# The result is stored in the variable 'phrases'\n",
        "# This operation assumes 'data' is a string containing natural language text\n",
        "phrases = sent_tokenize(data)\n",
        "\n",
        "# Use the word_tokenize function to split the content of the same 'data' variable into individual words\n",
        "# The result is stored in the variable 'words'\n",
        "# This also assumes 'data' is a string containing natural language text\n",
        "words = word_tokenize(data)\n",
        "\n",
        "# Print the list of tokenized sentences stored in 'phrases'\n",
        "print(phrases)\n",
        "\n",
        "# Print the list of tokenized words stored in 'words'\n",
        "print(words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDaff09uYNmB",
        "outputId": "99c27147-3f89-4170-e480-5f780a9443c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['As you get older, you know what you like and what is suitable for your body.', 'I like all Dove products.', 'Gives you that fresh all over, wide awake feeling and no dandruff or flakey skin.', 'No smelly a/pits!']\n",
            "['As', 'you', 'get', 'older', ',', 'you', 'know', 'what', 'you', 'like', 'and', 'what', 'is', 'suitable', 'for', 'your', 'body', '.', 'I', 'like', 'all', 'Dove', 'products', '.', 'Gives', 'you', 'that', 'fresh', 'all', 'over', ',', 'wide', 'awake', 'feeling', 'and', 'no', 'dandruff', 'or', 'flakey', 'skin', '.', 'No', 'smelly', 'a/pits', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stop-Word Removal\n",
        "\n",
        "> This code snippet prepares for natural language processing tasks by importing necessary functions and resources from the NLTK library. sent_tokenize and word_tokenize are for tokenizing text into sentences and words, while stopwords provide a list of common words often excluded in text analysis to focus on more meaningful words. The last line ensures that the stopwords data is downloaded and available."
      ],
      "metadata": {
        "id": "fPgQt4DhYuzi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the stopwords collection from the nltk.corpus module\n",
        "# Stopwords are common words like 'the', 'is', 'in', etc., that are often filtered out in natural language processing tasks\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the 'stopwords' resource from the NLTK data repository\n",
        "# This resource is a collection of stopwords for various languages and is necessary for stopwords filtering tasks\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yirYJCmeaibR",
        "outputId": "35ab6014-4903-4c14-d1e3-26ea00a69b17"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> This code snippet filters out common stopwords from a given text (data). It first tokenizes the text into words and then checks each word against predefined stopwords (common words that usually do not carry significant meaning in text analysis). The words not in the stopwords list are then collected in words filtered. The final output includes the count and list of stopwords and the filtered words from the input text. This process is helpful in many text analysis tasks where the focus is on the meaningful content of the text."
      ],
      "metadata": {
        "id": "GbRJtVDwyLOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a set of English stopwords by using the stopwords.words function from the NLTK library\n",
        "# This set contains common words like 'the', 'is', 'in', etc., that are typically removed in language processing\n",
        "stopWords = set(stopwords.words('english'))\n",
        "\n",
        "# Tokenize the 'data' string into words after converting it to lowercase\n",
        "# This ensures that the tokenization is case-insensitive\n",
        "words = word_tokenize(data.lower())\n",
        "\n",
        "# Initialize an empty list to store the filtered words\n",
        "wordsFiltered = []\n",
        "\n",
        "# Iterate over each word in the tokenized 'words' list\n",
        "for w in words:\n",
        "    # Check if the word is not in the set of stopwords\n",
        "    if w not in stopWords:\n",
        "        # If the word is not a stopword, append it to the 'wordsFiltered' list\n",
        "        wordsFiltered.append(w)\n",
        "\n",
        "# Print the total number of stopwords in the stopWords set\n",
        "print(len(stopWords))\n",
        "\n",
        "# Print the set of English stopwords\n",
        "print(stopWords)\n",
        "\n",
        "# Print the list of words filtered out from the 'data' string, excluding stopwords\n",
        "print(wordsFiltered)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9ssTJlCYx5h",
        "outputId": "da7b3f8b-c688-4997-d063-935f7be4642c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "179\n",
            "{'s', 'an', 'if', 'and', 'yourselves', 'our', 'have', 'y', 'below', \"don't\", 'against', 'having', \"mustn't\", 'were', 'does', 'herself', 'than', 'such', 'now', \"weren't\", 'through', 'above', 'how', 'ourselves', \"won't\", 'myself', 'for', 'didn', \"shouldn't\", \"shan't\", 'these', \"should've\", 're', \"didn't\", \"it's\", \"wasn't\", \"you're\", 'as', \"mightn't\", 'needn', 'do', 'some', 'or', 'will', 'again', 'where', 'aren', 'theirs', 'any', 'up', 'o', 'off', 'a', 'to', 'between', \"you'd\", 'while', 'into', 'about', 'under', 'what', 'they', 'your', 'own', 'too', 'no', \"doesn't\", 'was', 'not', 'by', 'been', \"couldn't\", \"haven't\", 'more', 'which', 'is', 'there', 'when', 'wouldn', 'he', 'during', 've', 'then', 'ain', 'but', 'don', 'ma', 'should', \"you'll\", 'further', 'shouldn', 'their', 'down', 'few', 'haven', 'its', 'had', 'nor', 'out', 'd', 'in', 'i', 'here', 'same', 'before', 'doing', 't', \"aren't\", \"isn't\", \"hasn't\", 'am', 'his', 'me', 'it', 'she', 'other', 'hadn', 'did', 'her', \"that'll\", 'whom', \"wouldn't\", 'on', 'shan', 'being', 'you', 'them', 'so', 'couldn', 'itself', 'with', 'ours', 'wasn', 'the', 'very', 'after', 'mightn', 'all', 'm', 'yours', 'we', 'why', 'weren', 'themselves', 'are', 'most', 'yourself', 'won', 'this', 'at', 'those', 'has', 'doesn', 'that', 'isn', 'once', 'just', 'my', 'hers', 'until', 'of', 'him', 'can', 'who', \"you've\", \"hadn't\", 'himself', 'both', 'over', 'only', \"needn't\", 'mustn', \"she's\", 'from', 'hasn', 'll', 'be', 'each', 'because'}\n",
            "['get', 'older', ',', 'know', 'like', 'suitable', 'body', '.', 'like', 'dove', 'products', '.', 'gives', 'fresh', ',', 'wide', 'awake', 'feeling', 'dandruff', 'flakey', 'skin', '.', 'smelly', 'a/pits', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming\n",
        "\n",
        "> This code snippet is set up for text-processing tasks using the Natural Language Toolkit (NLTK) in Python. It imports the PorterStemmer class, which is a popular stemming algorithm used to reduce words to their base or root form (for example, \"running\" to \"run\"). This can be useful in various natural language processing applications where the specific form of a word is less important than its core meaning. The snippet also imports sent_tokenize and word_tokenize, which are used for breaking text down into sentences and words, respectively, an essential step in many text analysis tasks.\n"
      ],
      "metadata": {
        "id": "dpIt2NACcX1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the PorterStemmer class from the nltk.stem module\n",
        "# PorterStemmer is used for stemming, which is the process of reducing words to their word stem or root form\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Import the sent_tokenize and word_tokenize functions from the nltk.tokenize module\n",
        "# sent_tokenize is used for splitting text into sentences, while word_tokenize is used for splitting sentences into words\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n"
      ],
      "metadata": {
        "id": "Ln0kH7n4cZhN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stem the Words\n",
        "\n",
        "> In this code snippet, we are creating an instance of the PorterStemmer class from the NLTK library, which implements the Porter stemming algorithm. This algorithm is widely used for stemming in English, which involves reducing words to their root form. For example, the stemmer might reduce the word \"running\" to \"run\". The for loop iterates over each word in the list of words and prints its stemmed version for each word. This process is helpful in natural language processing tasks where we want to consider word usage in a more general sense, without the specifics of tense, plurality, etc."
      ],
      "metadata": {
        "id": "EwAzQY5od0Gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize an instance of the PorterStemmer class\n",
        "# This stemmer is used to reduce words to their base or root form\n",
        "ps = PorterStemmer()\n",
        "\n",
        "# Iterate through each word in the 'words' list.\n",
        "# This list should contain individual words that are possibly tokenized from some text\n",
        "for word in words:\n",
        "    # Print the stemmed version of each word\n",
        "    # The stem() method of the PorterStemmer instance reduces the word to its root form\n",
        "    print(ps.stem(word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VafJKYVTdQfI",
        "outputId": "c80e0428-d2fd-40b8-83c5-585e0304c5f8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "as\n",
            "you\n",
            "get\n",
            "older\n",
            ",\n",
            "you\n",
            "know\n",
            "what\n",
            "you\n",
            "like\n",
            "and\n",
            "what\n",
            "is\n",
            "suitabl\n",
            "for\n",
            "your\n",
            "bodi\n",
            ".\n",
            "i\n",
            "like\n",
            "all\n",
            "dove\n",
            "product\n",
            ".\n",
            "give\n",
            "you\n",
            "that\n",
            "fresh\n",
            "all\n",
            "over\n",
            ",\n",
            "wide\n",
            "awak\n",
            "feel\n",
            "and\n",
            "no\n",
            "dandruff\n",
            "or\n",
            "flakey\n",
            "skin\n",
            ".\n",
            "no\n",
            "smelli\n",
            "a/pit\n",
            "!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stem the Sentences\n",
        "\n",
        "> In this code snippet, we are iterating over each word in the word list. We print a combination of the original word and its stemmed version for each word, with a colon (\":\") separating the two. This output format makes it easy to compare the original word with its stemmed form, helping to understand how the stemming process changes each word. The ps.stem(word) call applies the Porter stemming algorithm to reduce each word to its root form. It is a common practice in many natural language processing tasks to generalize and simplify text data."
      ],
      "metadata": {
        "id": "aVp3YpgKd4bS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate through each word in the 'words' list\n",
        "# This list should contain individual words that are possibly tokenized from some text\n",
        "for word in words:\n",
        "    # For each word, print the original word and its stemmed version, separated by a colon\n",
        "    # The stem() method of the PorterStemmer instance 'ps' reduces the word to its root form\n",
        "    print(word + \":\" + ps.stem(word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v9_4MjSd8fG",
        "outputId": "bf66dcf3-47d4-496a-cbad-15532933da79"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "as:as\n",
            "you:you\n",
            "get:get\n",
            "older:older\n",
            ",:,\n",
            "you:you\n",
            "know:know\n",
            "what:what\n",
            "you:you\n",
            "like:like\n",
            "and:and\n",
            "what:what\n",
            "is:is\n",
            "suitable:suitabl\n",
            "for:for\n",
            "your:your\n",
            "body:bodi\n",
            ".:.\n",
            "i:i\n",
            "like:like\n",
            "all:all\n",
            "dove:dove\n",
            "products:product\n",
            ".:.\n",
            "gives:give\n",
            "you:you\n",
            "that:that\n",
            "fresh:fresh\n",
            "all:all\n",
            "over:over\n",
            ",:,\n",
            "wide:wide\n",
            "awake:awak\n",
            "feeling:feel\n",
            "and:and\n",
            "no:no\n",
            "dandruff:dandruff\n",
            "or:or\n",
            "flakey:flakey\n",
            "skin:skin\n",
            ".:.\n",
            "no:no\n",
            "smelly:smelli\n",
            "a/pits:a/pit\n",
            "!:!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# N-grams"
      ],
      "metadata": {
        "id": "Jx9umGJjfioo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word N-grams\n",
        "\n",
        "> The ngrams function in the NLTK library helps generate n-grams from text. N-grams are contiguous sequences of 'n' items (where 'n' is a specified number) from the text. For example, in text processing, these items are usually words, so a 2-gram (or bigram) would consist of pairs of consecutive words from the text. N-grams are used in various natural language processing tasks, such as text analysis and linguistic research, and as a part of algorithms for text prediction, search, and machine learning models in language processing."
      ],
      "metadata": {
        "id": "VGisQGNbh30D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the ngrams function from the nltk module\n",
        "# The ngrams function is used to generate n-grams from a given sequence of items (like words in a text)\n",
        "# An n-gram is a contiguous sequence of n items from a given sample of text or speech\n",
        "from nltk import ngrams\n"
      ],
      "metadata": {
        "id": "Bj-_q-wIfuAp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first element (sentence) from the list 'phrases'\n",
        "# This assumes that 'phrases' is a list of sentences obtained from a previous sentence tokenization process\n",
        "print(phrases[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_9lqWMIhIYi",
        "outputId": "1035d45c-97ff-421e-8048-40ef7440aee1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As you get older, you know what you like and what is suitable for your body.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> This code snippet generates 6-grams from the first sentence in the phrases list. The ngrams function from NLTK takes a list of items (in this case, words from the first sentence) and an integer n, producing an iterator over n-grams. We have chosen 6-grams here so that the function will produce tuples of six consecutive words from the sentence. These 6-grams are helpful in natural language processing and computational linguistics to analyse the context in which words appear and understand language patterns. The for loop then iterates over these 6-grams, printing each in turn."
      ],
      "metadata": {
        "id": "lF7l6Eo02Tcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the number 'n' for the n-grams. In this case, n is set to 6 for generating 6-grams\n",
        "n = 6\n",
        "\n",
        "# Create 6-grams from the first sentence in the 'phrases' list\n",
        "# The sentence is first split into words using the split() method, then ngrams() function is applied\n",
        "# This results in an iterator over 6-word tuples from the sentence\n",
        "w_6grams = ngrams(phrases[0].split(), n)\n",
        "\n",
        "# Iterate over each 6-gram in the w_6grams\n",
        "for grams in w_6grams:\n",
        "    # Print each 6-gram\n",
        "    # Each 6-gram is a tuple of 6 words that occur consecutively in the sentence\n",
        "    print(grams)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuaVXFs7fz48",
        "outputId": "b060f465-5a6b-4bf3-c6a4-2e3f641b9aa4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('As', 'you', 'get', 'older,', 'you', 'know')\n",
            "('you', 'get', 'older,', 'you', 'know', 'what')\n",
            "('get', 'older,', 'you', 'know', 'what', 'you')\n",
            "('older,', 'you', 'know', 'what', 'you', 'like')\n",
            "('you', 'know', 'what', 'you', 'like', 'and')\n",
            "('know', 'what', 'you', 'like', 'and', 'what')\n",
            "('what', 'you', 'like', 'and', 'what', 'is')\n",
            "('you', 'like', 'and', 'what', 'is', 'suitable')\n",
            "('like', 'and', 'what', 'is', 'suitable', 'for')\n",
            "('and', 'what', 'is', 'suitable', 'for', 'your')\n",
            "('what', 'is', 'suitable', 'for', 'your', 'body.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Character N-grams"
      ],
      "metadata": {
        "id": "xj5IG15FiBZL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set 'n' to 6 for generating 6-grams\n",
        "n = 6\n",
        "\n",
        "# Create 6-grams from the first sentence in the 'phrases' list, but this time treating the sentence as a sequence of characters\n",
        "# The ngrams() function is applied directly to the string, resulting in an iterator over 6-character tuples from the sentence\n",
        "c_6grams = ngrams(phrases[0], n)\n",
        "\n",
        "# Iterate over each 6-gram in the c_6grams\n",
        "for grams in c_6grams:\n",
        "    # Join the tuple of characters into a string and print it\n",
        "    # Each 6-gram here is a sequence of 6 consecutive characters (including spaces and punctuation) from the sentence\n",
        "    print(''.join(grams))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KwQm-PMDiFPN",
        "outputId": "1a709468-ecb6-44a0-fbc1-1ba6a16fc638"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As you\n",
            "s you \n",
            " you g\n",
            "you ge\n",
            "ou get\n",
            "u get \n",
            " get o\n",
            "get ol\n",
            "et old\n",
            "t olde\n",
            " older\n",
            "older,\n",
            "lder, \n",
            "der, y\n",
            "er, yo\n",
            "r, you\n",
            ", you \n",
            " you k\n",
            "you kn\n",
            "ou kno\n",
            "u know\n",
            " know \n",
            "know w\n",
            "now wh\n",
            "ow wha\n",
            "w what\n",
            " what \n",
            "what y\n",
            "hat yo\n",
            "at you\n",
            "t you \n",
            " you l\n",
            "you li\n",
            "ou lik\n",
            "u like\n",
            " like \n",
            "like a\n",
            "ike an\n",
            "ke and\n",
            "e and \n",
            " and w\n",
            "and wh\n",
            "nd wha\n",
            "d what\n",
            " what \n",
            "what i\n",
            "hat is\n",
            "at is \n",
            "t is s\n",
            " is su\n",
            "is sui\n",
            "s suit\n",
            " suita\n",
            "suitab\n",
            "uitabl\n",
            "itable\n",
            "table \n",
            "able f\n",
            "ble fo\n",
            "le for\n",
            "e for \n",
            " for y\n",
            "for yo\n",
            "or you\n",
            "r your\n",
            " your \n",
            "your b\n",
            "our bo\n",
            "ur bod\n",
            "r body\n",
            " body.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploring Corpora"
      ],
      "metadata": {
        "id": "5WLkJCFhiuxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import FreqDist\n",
        "from nltk.tokenize import word_tokenize\n"
      ],
      "metadata": {
        "id": "L2xokoK6ixlN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fdist1 = FreqDist(words)\n",
        "print(fdist1.most_common(2)) # Prints two most common tokens\n",
        "print(fdist1.hapaxes())      # Prints tokens with frequency 1\n"
      ],
      "metadata": {
        "id": "beTUDCFjjy-y",
        "outputId": "6950b8dd-3175-498e-c106-ba5da3459908",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('you', 4), ('.', 3)]\n",
            "['as', 'get', 'older', 'know', 'is', 'suitable', 'for', 'your', 'body', 'i', 'dove', 'products', 'gives', 'that', 'fresh', 'over', 'wide', 'awake', 'feeling', 'dandruff', 'or', 'flakey', 'skin', 'smelly', 'a/pits', '!']\n"
          ]
        }
      ]
    }
  ]
}